{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytimetk\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytimetk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytimetk as pytimetk\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date, timedelta \n",
    "from datetime import date, timedelta \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# File Path\n",
    "\n",
    "\n",
    "max_temp_file_path = 'G:/fresh_start/main_thesis/data/raw/Max_temp.xlsx'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading workbook\n",
    "initial_max_temp_df = pd.ExcelFile(max_temp_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For maximum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_file_column_order =  [ 'Station Index', 'Max T']\n",
    "initial_max_dict = {}\n",
    "# Iterate over each sheet and create a DataFrame\n",
    "for sheet_name in initial_max_temp_df.sheet_names:\n",
    "    max_df_parsed = initial_max_temp_df.parse(sheet_name)\n",
    "\n",
    "    initial_max_dict[sheet_name] = max_df_parsed\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "     # Converting a Year , Month and Day Column into Date column\n",
    "    max_df_parsed['Date'] = pd.to_datetime(max_df_parsed[['Year', 'Month', 'Day']])\n",
    "\n",
    "    \n",
    "\n",
    "    # Set \"Date\" as the index column\n",
    "    max_df_parsed.set_index('Date', inplace=True)\n",
    "\n",
    "    max_df_parsed = max_df_parsed[max_file_column_order]\n",
    "    \n",
    "    max_df_parsed= max_df_parsed.rename(columns={'Station Index': 'Station'})\n",
    "    \n",
    "    initial_max_dict[sheet_name] = max_df_parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_station_as_it_is_data_frame_1 = []\n",
    "for station_name, max_temp_df in initial_max_dict.items():\n",
    "    max_temp_df.loc[:, 'Station'] = station_name\n",
    "    all_station_as_it_is_data_frame_1.append(max_temp_df)\n",
    "\n",
    "\n",
    "all_station_as_it_is_data_frame_2 = pd.concat(all_station_as_it_is_data_frame_1, ignore_index=False)\n",
    "\n",
    "all_station_as_it_is_data_frame_2['Max T'] = all_station_as_it_is_data_frame_2['Max T'].replace('NA', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_outlier_check_dict = {}\n",
    "\n",
    "for station_name, df_max_temp in initial_max_dict.items():\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate the IQR for 'Max T' column\n",
    "    Q1 = df_max_temp['Max T'].quantile(0.25)\n",
    "    Q3 = df_max_temp['Max T'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter out data points outside the bounds\n",
    "    df_max_temp = df_max_temp[(df_max_temp['Max T'] >= lower_bound) & (df_max_temp['Max T'] <= upper_bound)]\n",
    "    max_outlier_check_dict[station_name]=df_max_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_temp_data( station_code):\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Generate random temperature data for each day within the date range\n",
    "    current_date = date(1962, 1, 1)\n",
    "    while current_date <= date(2022, 12, 31):\n",
    "        temperature = round(random.uniform(1900, 2000), 1)\n",
    "        data.append([current_date, station_code, temperature])\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Create a DataFrame from the generated data\n",
    "    dummy_temp_df = pd.DataFrame(data, columns=['Date', 'Station', 'Max_Temp'])\n",
    "\n",
    "    # Set the 'Date' column as the index\n",
    "    #dummy_temp_df.set_index('Date', inplace=True)\n",
    "\n",
    "    return dummy_temp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_1960_2022_initial = {}\n",
    "\n",
    "for station_name, max_temp_df in max_outlier_check_dict.items():\n",
    "    \n",
    "    max_temp_df = max_temp_df.reset_index()\n",
    "    max_temp_df['Date'] = pd.to_datetime(max_temp_df['Date'])\n",
    "    \n",
    "    dummy_temp_df = generate_dummy_temp_data(station_name)\n",
    "    \n",
    "    dummy_temp_df['Date'] = pd.to_datetime(dummy_temp_df['Date'])\n",
    "    \n",
    "    df3 = pd.merge(dummy_temp_df, max_temp_df, on=['Date'], how='left').fillna('NA')\n",
    "    \n",
    "    \n",
    "    max_temp_1960_2022_initial[station_name] = df3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_name, max_temp_df in max_temp_1960_2022_initial.items():\n",
    "    max_temp_df = max_temp_df[['Date', 'Max T']]\n",
    "    max_temp_1960_2022_initial[station_name] = max_temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing data frames\n",
    "all_station_data_initial_df = []\n",
    "\n",
    "for station_name, max_temp_df in max_temp_1960_2022_initial.items():\n",
    "    max_temp_df.loc[:, 'Station'] = station_name\n",
    "    all_station_data_initial_df.append(max_temp_df)\n",
    "\n",
    "result_df_max_temp = pd.concat(all_station_data_initial_df, ignore_index=True)\n",
    "\n",
    "result_df_max_temp = result_df_max_temp[['Date', 'Station', 'Max T']]\n",
    "# Replace 'NA' with NaN\n",
    "result_df_max_temp['Max T'] = result_df_max_temp['Max T'].replace('NA', np.nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df_max_temp['Date'] = pd.to_datetime(result_df_max_temp['Date'])\n",
    "\n",
    "start_date = pd.to_datetime('1990-01-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Filter the DataFrame to include data within the specified date range\n",
    "filtered_data_df = result_df_max_temp[(result_df_max_temp['Date'] >= start_date) & (result_df_max_temp['Date'] <= end_date)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_dict_by_month1 = {}\n",
    "unique_months_max_df = filtered_data_df['Date'].dt.month.unique()\n",
    "\n",
    "for month in unique_months_max_df:\n",
    "    monthly_max_temp = filtered_data_df[filtered_data_df['Date'].dt.month == month].copy()\n",
    "    \n",
    "    monthly_max_temp = monthly_max_temp.reindex()\n",
    "    \n",
    "    max_temp_dict_by_month1[month] = monthly_max_temp\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_missing_with_regression(df, target_column, feature_columns):\n",
    "    # Split data into training and prediction data\n",
    "    training_data = df.dropna(subset=[target_column] + feature_columns)\n",
    "    prediction_data = df[df[target_column].isna()]\n",
    "\n",
    "    # Create and train a regression model\n",
    "    X_train = training_data[feature_columns]\n",
    "    y_train = training_data[target_column]\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict missing values\n",
    "    X_pred = prediction_data[feature_columns]\n",
    "    predicted_values = regression_model.predict(X_pred)\n",
    "\n",
    "    # Impute missing values in the original DataFrame\n",
    "    df.loc[df[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regression_ready_dict ={}\n",
    "for month_name, month_df in max_temp_dict_by_month1.items():\n",
    "    # Pivot the DataFrame\n",
    "    pivoted_df = month_df.pivot_table(index='Station' , columns=['Date'], values='Max T')\n",
    "    \n",
    "    # Pivot the DataFrame\n",
    "    #pivoted_df = month_df.pivot_table(index='Date' , columns=['Station'], values='Max T')\n",
    "    \n",
    "    \n",
    "    # Replace 'NA' with actual NaN values\n",
    "    pivoted_df.replace('NaN', np.nan, inplace=True)\n",
    "    \n",
    "    # Update the dictionary with the pivoted DataFrame\n",
    "    max_regression_ready_dict[month_name] = pivoted_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regression_1_dict ={}\n",
    "for month_name, month_df in max_regression_ready_dict.items():\n",
    "    \n",
    "    # Step 1: Find the column with the minimum number of missing values\n",
    "    value_missing_onlyone_column = month_df.isna().sum().idxmin()\n",
    "    \n",
    "    #print(value_missing_onlyone_column)\n",
    "    \n",
    "    # Step 2: Calculate the average of the selected column\n",
    "    average_value = month_df[value_missing_onlyone_column].mean()\n",
    "    \n",
    "    #print(average_value)\n",
    "\n",
    "    # Step 3: Replace NaN values in the selected column with the calculated average\n",
    "    month_df[value_missing_onlyone_column].fillna(average_value, inplace=True)\n",
    "    max_regression_1_dict[month_name] = month_df\n",
    "    #print(month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_regression_12_dict ={}\n",
    "for month_name, month_df in max_regression_1_dict.items():\n",
    "    \n",
    "    # Get a list of all column names except the target columns\n",
    "    target_columns = month_df.columns[month_df.isna().any()].tolist()\n",
    "    feature_columns = [col for col in month_df.columns if col not in target_columns]\n",
    "\n",
    "    # Iterate over target columns and impute missing values using regression\n",
    "    for target_col in target_columns:\n",
    "        impute_missing_with_regression(month_df, target_col, feature_columns)\n",
    "        \n",
    "    max_regression_12_dict[month_name]=month_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regression_123_dict ={}\n",
    "for month_name, month_df in max_regression_12_dict.items():\n",
    "    df_melted_df = month_df.reset_index().melt(id_vars =['Station'], \n",
    "                         var_name ='Date', value_name = 'Max T')\n",
    "    \n",
    "    df_melted_df = df_melted_df[['Date', 'Station','Max T']]\n",
    "    \n",
    "    max_regression_123_dict[month_name] = df_melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "concatenated_df_filled_1990 = pd.concat(max_regression_123_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_filled_1990 = concatenated_df_filled_1990.set_index('Station')\n",
    "station_sort_filled_1990 = station_filled_1990.sort_values(by=['Station', 'Date'], ascending=[True, True])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(initial_min_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_sort_filled_1990.to_csv('G:/fresh_start/main_thesis/data/temp_data/station_sort_filled_1990.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
