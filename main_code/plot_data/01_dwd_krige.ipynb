{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Kriging geographical data\n",
        "\n",
        "In this example we are going to interpolate actual temperature data from\n",
        "the German weather service [DWD](https://www.dwd.de/EN).\n",
        "\n",
        "Data is retrieved utilizing the beautiful package\n",
        "[wetterdienst](https://github.com/earthobservations/wetterdienst),\n",
        "which serves as an API for the DWD data.\n",
        "\n",
        "For better visualization, we also download a simple shapefile of the German\n",
        "borderline with [cartopy](https://github.com/SciTools/cartopy).\n",
        "\n",
        "In order to keep the number of dependecies low, the calls of both functions\n",
        "shown beneath are commented out.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import gstools as gs\n",
        "\n",
        "\n",
        "def get_borders_germany():\n",
        "    \"\"\"Download simple german shape file with cartopy.\"\"\"\n",
        "    import geopandas as gp  # 0.8.1\n",
        "    from cartopy.io import shapereader as shp_read  # version 0.18.0\n",
        "\n",
        "    shpfile = shp_read.natural_earth(\"50m\", \"cultural\", \"admin_0_countries\")\n",
        "    df = gp.read_file(shpfile)  # only use the simplest polygon\n",
        "    poly = df.loc[df[\"ADMIN\"] == \"Germany\"][\"geometry\"].values[0][0]\n",
        "    np.savetxt(\"de_borders.txt\", list(poly.exterior.coords))\n",
        "\n",
        "\n",
        "def get_dwd_temperature(date=\"2020-06-09 12:00:00\"):\n",
        "    \"\"\"Get air temperature from german weather stations from 9.6.20 12:00.\"\"\"\n",
        "    from wetterdienst.dwd import observations as obs  # version 0.13.0\n",
        "\n",
        "    settings = dict(\n",
        "        resolution=obs.DWDObservationResolution.HOURLY,\n",
        "        start_date=date,\n",
        "        end_date=date,\n",
        "    )\n",
        "    sites = obs.DWDObservationStations(\n",
        "        parameter_set=obs.DWDObservationParameterSet.TEMPERATURE_AIR,\n",
        "        period=obs.DWDObservationPeriod.RECENT,\n",
        "        **settings,\n",
        "    )\n",
        "    ids, lat, lon = sites.all().loc[:, [\"STATION_ID\", \"LAT\", \"LON\"]].values.T\n",
        "    observations = obs.DWDObservationData(\n",
        "        station_ids=ids,\n",
        "        parameters=obs.DWDObservationParameter.HOURLY.TEMPERATURE_AIR_200,\n",
        "        periods=obs.DWDObservationPeriod.RECENT,\n",
        "        **settings,\n",
        "    )\n",
        "    temp = observations.all().VALUE.values\n",
        "    sel = np.isfinite(temp)\n",
        "    # select only valid temperature data\n",
        "    ids, lat, lon, temp = ids.astype(float)[sel], lat[sel], lon[sel], temp[sel]\n",
        "    head = \"id, lat, lon, temp\"  # add a header to the file\n",
        "    np.savetxt(\"temp_obs.txt\", np.array([ids, lat, lon, temp]).T, header=head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to download the data again,\n",
        "uncomment the two following lines. We will simply load the resulting\n",
        "files to gain the border polygon and the observed temperature along with\n",
        "the station locations given by lat-lon values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Administrator\\anaconda3\\envs\\paper_env\\Lib\\site-packages\\cartopy\\io\\__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_countries.zip\n",
            "  warnings.warn(f'Downloading: {url}', DownloadWarning)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'MultiPolygon' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_borders_germany\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m get_dwd_temperature(date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-06-09 12:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m border \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mde_borders.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mget_borders_germany\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m shpfile \u001b[38;5;241m=\u001b[39m shp_read\u001b[38;5;241m.\u001b[39mnatural_earth(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcultural\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madmin_0_countries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mread_file(shpfile)  \u001b[38;5;66;03m# only use the simplest polygon\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m poly \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADMIN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGermany\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mde_borders.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(poly\u001b[38;5;241m.\u001b[39mexterior\u001b[38;5;241m.\u001b[39mcoords))\n",
            "\u001b[1;31mTypeError\u001b[0m: 'MultiPolygon' object is not subscriptable"
          ]
        }
      ],
      "source": [
        " get_borders_germany()\n",
        "get_dwd_temperature(date=\"2020-06-09 12:00:00\")\n",
        "\n",
        "border = np.loadtxt(\"de_borders.txt\")\n",
        "ids, lat, lon, temp = np.loadtxt(\"temp_obs.txt\").T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we will estimate the variogram of our temperature data.\n",
        "As the maximal bin distance we choose 900 km.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bin_center, vario = gs.vario_estimate(\n",
        "    (lat, lon), temp, latlon=True, geo_scale=gs.KM_SCALE, max_dist=900\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can use this estimated variogram to fit a model to it.\n",
        "Here we will use a :any:`Spherical` model. We select the ``latlon`` option\n",
        "to use the `Yadrenko` variant of the model to gain a valid model for lat-lon\n",
        "coordinates and we set the ``geo_scale`` to the earth-radius. Otherwise the length\n",
        "scale would be given in radians representing the great-circle distance.\n",
        "\n",
        "We deselect the nugget from fitting and plot the result afterwards.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>You need to plot the Yadrenko variogram, since the standard variogram\n",
        "   still holds the ordinary routine that is not respecting the great-circle\n",
        "   distance.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = gs.Spherical(latlon=True, geo_scale=gs.KM_SCALE)\n",
        "model.fit_variogram(bin_center, vario, nugget=False)\n",
        "ax = model.plot(\"vario_yadrenko\", x_max=max(bin_center))\n",
        "ax.scatter(bin_center, vario)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see, we have a rather large correlation length of 600 km.\n",
        "\n",
        "Now we want to interpolate the data using :any:`Universal` kriging.\n",
        "In order to tinker around with the data, we will use a north-south drift\n",
        "by assuming a linear correlation with the latitude.\n",
        "This can be done as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def north_south_drift(lat, lon):\n",
        "    return lat\n",
        "\n",
        "\n",
        "uk = gs.krige.Universal(\n",
        "    model=model,\n",
        "    cond_pos=(lat, lon),\n",
        "    cond_val=temp,\n",
        "    drift_functions=north_south_drift,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we generate the kriging field, by defining a lat-lon grid that covers\n",
        "the whole of Germany. The :any:`Krige` class provides the option to only\n",
        "krige the mean field, so one can have a glimpse at the estimated drift.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g_lat = np.arange(47, 56.1, 0.1)\n",
        "g_lon = np.arange(5, 16.1, 0.1)\n",
        "\n",
        "uk.set_pos((g_lat, g_lon), mesh_type=\"structured\")\n",
        "uk(return_var=False, store=\"temp_field\")\n",
        "uk(only_mean=True, store=\"mean_field\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it. Now let's have a look at the generated field and the input\n",
        "data along with the estimated mean:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "levels = np.linspace(5, 23, 64)\n",
        "fig, ax = plt.subplots(1, 3, figsize=[10, 5], sharey=True)\n",
        "sca = ax[0].scatter(lon, lat, c=temp, vmin=5, vmax=23, cmap=\"coolwarm\")\n",
        "co1 = ax[1].contourf(g_lon, g_lat, uk[\"temp_field\"], levels, cmap=\"coolwarm\")\n",
        "co2 = ax[2].contourf(g_lon, g_lat, uk[\"mean_field\"], levels, cmap=\"coolwarm\")\n",
        "\n",
        "[ax[i].plot(border[:, 0], border[:, 1], color=\"k\") for i in range(3)]\n",
        "[ax[i].set_xlim([5, 16]) for i in range(3)]\n",
        "[ax[i].set_xlabel(\"Lon in deg\") for i in range(3)]\n",
        "ax[0].set_ylabel(\"Lat in deg\")\n",
        "\n",
        "ax[0].set_title(\"Temperature observations at 2m\\nfrom DWD (2020-06-09 12:00)\")\n",
        "ax[1].set_title(\"Interpolated temperature\\nwith North-South drift\")\n",
        "ax[2].set_title(\"Estimated mean drift\\nfrom Universal Kriging\")\n",
        "\n",
        "fmt = dict(orientation=\"horizontal\", shrink=0.5, fraction=0.1, pad=0.2)\n",
        "fig.colorbar(co2, ax=ax, **fmt).set_label(\"T in [°C]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a better impression of the estimated north-south drift, we'll take\n",
        "a look at a cross-section at a longitude of 10 degree:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(g_lat, uk[\"temp_field\"][:, 50], label=\"Interpolated temperature\")\n",
        "ax.plot(g_lat, uk[\"mean_field\"][:, 50], label=\"North-South mean drift\")\n",
        "ax.set_xlabel(\"Lat in deg\")\n",
        "ax.set_ylabel(\"T in [°C]\")\n",
        "ax.set_title(\"North-South cross-section at 10°\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretion of the results is now up to you! ;-)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
