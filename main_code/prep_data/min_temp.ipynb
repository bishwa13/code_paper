{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytimetk as pytimetk\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date, timedelta \n",
    "from datetime import date, timedelta \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "min_temp_file_path = 'G:/fresh_start/main_thesis/data/raw/Min_temp.xlsx'\n",
    "\n",
    "\n",
    "intial_min_temp_df = pd.ExcelFile(min_temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_file_column_order =  [ 'Station NO', 'Min T']\n",
    "initial_min_dict = {}\n",
    "# Iterate over each sheet and create a DataFrame\n",
    "for sheet_name in intial_min_temp_df.sheet_names:\n",
    "    min_df_parsed = intial_min_temp_df.parse(sheet_name)\n",
    "\n",
    "    initial_min_dict[sheet_name] = min_df_parsed\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "     # Converting a Year , Month and Day Column into Date column\n",
    "    min_df_parsed['Date'] = pd.to_datetime(min_df_parsed[['Year', 'Month', 'Day']])\n",
    "\n",
    "    \n",
    "\n",
    "    # Set \"Date\" as the index column\n",
    "    min_df_parsed.set_index('Date', inplace=True)\n",
    "\n",
    "    min_df_parsed = min_df_parsed[min_file_column_order]\n",
    "    \n",
    "    min_df_parsed= min_df_parsed.rename(columns={'Station NO': 'Station'})\n",
    "    \n",
    "    initial_min_dict[sheet_name] = min_df_parsed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_outlier_check_dict = {}\n",
    "\n",
    "for station_name, df_min_temp in initial_min_dict.items():\n",
    "    # Calculate the IQR for 'Min T' column (replace 'Max T' with 'Min T')\n",
    "    Q1 = df_min_temp['Min T'].quantile(0.25)  # Change 'Max T' to 'Min T'\n",
    "    Q3 = df_min_temp['Min T'].quantile(0.75)  # Change 'Max T' to 'Min T'\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter out data points outside the bounds\n",
    "    df_min_temp = df_min_temp[(df_min_temp['Min T'] >= lower_bound) & (df_min_temp['Min T'] <= upper_bound)]  # Change 'Max T' to 'Min T'\n",
    "    min_outlier_check_dict[station_name] = df_min_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_temp_data( station_code):\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Generate random temperature data for each day within the date range\n",
    "    current_date = date(1962, 1, 1)\n",
    "    while current_date <= date(2022, 12, 31):\n",
    "        temperature = round(random.uniform(1900, 2000), 1)\n",
    "        data.append([current_date, station_code, temperature])\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Create a DataFrame from the generated data\n",
    "    dummy_temp_df = pd.DataFrame(data, columns=['Date', 'Station', 'Max_Temp'])\n",
    "\n",
    "    # Set the 'Date' column as the index\n",
    "    #dummy_temp_df.set_index('Date', inplace=True)\n",
    "\n",
    "    return dummy_temp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp_1960_2022_initial = {}\n",
    "\n",
    "for station_name, min_temp_df in min_outlier_check_dict.items():\n",
    "    \n",
    "    min_temp_df = min_temp_df.reset_index()\n",
    "    min_temp_df['Date'] = pd.to_datetime(min_temp_df['Date'])\n",
    "    \n",
    "    dummy_temp_df = generate_dummy_temp_data(station_name)\n",
    "    \n",
    "    dummy_temp_df['Date'] = pd.to_datetime(dummy_temp_df['Date'])\n",
    "    \n",
    "    df3 = pd.merge(dummy_temp_df, min_temp_df, on=['Date'], how='left').fillna('NA')\n",
    "    \n",
    "    min_temp_1960_2022_initial[station_name] = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Max T' with 'Min T'\n",
    "for station_name, min_temp_df in min_temp_1960_2022_initial.items():\n",
    "    min_temp_df = min_temp_df[['Date', 'Min T']]\n",
    "    min_temp_1960_2022_initial[station_name] = min_temp_df\n",
    "\n",
    "# Initializing data frames\n",
    "all_station_data_initial_df = []\n",
    "\n",
    "for station_name, min_temp_df in min_temp_1960_2022_initial.items():\n",
    "    min_temp_df.loc[:, 'Station'] = station_name\n",
    "    all_station_data_initial_df.append(min_temp_df)\n",
    "\n",
    "result_df_min_temp = pd.concat(all_station_data_initial_df, ignore_index=True)\n",
    "\n",
    "result_df_min_temp = result_df_min_temp[['Date', 'Station', 'Min T']]\n",
    "# Replace 'NA' with NaN\n",
    "result_df_min_temp['Min T'] = result_df_min_temp['Min T'].replace('NA', np.nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_min_temp['Date'] = pd.to_datetime(result_df_min_temp['Date'])\n",
    "\n",
    "start_date = pd.to_datetime('1990-01-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Filter the DataFrame to include data within the specified date range\n",
    "filtered_data_df = result_df_min_temp[(result_df_min_temp['Date'] >= start_date) & (result_df_min_temp['Date'] <= end_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_missing_with_regression(df, target_column, feature_columns):\n",
    "    # Split data into training and prediction data\n",
    "    training_data = df.dropna(subset=[target_column] + feature_columns)\n",
    "    prediction_data = df[df[target_column].isna()]\n",
    "\n",
    "    # Create and train a regression model\n",
    "    X_train = training_data[feature_columns]\n",
    "    y_train = training_data[target_column]\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict missing values\n",
    "    X_pred = prediction_data[feature_columns]\n",
    "    predicted_values = regression_model.predict(X_pred)\n",
    "\n",
    "    # Impute missing values in the original DataFrame\n",
    "    df.loc[df[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp_dict_by_month1 = {}\n",
    "unique_months_min_df = filtered_data_df['Date'].dt.month.unique()\n",
    "\n",
    "for month in unique_months_min_df:\n",
    "    monthly_min_temp = filtered_data_df[filtered_data_df['Date'].dt.month == month].copy()\n",
    "    \n",
    "    monthly_min_temp = monthly_min_temp.reindex()\n",
    "    \n",
    "    min_temp_dict_by_month1[month] = monthly_min_temp\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    " \n",
    "min_regression_ready_dict = {}\n",
    "for month_name, month_df in min_temp_dict_by_month1.items():\n",
    "    # Pivot the DataFrame\n",
    "    pivoted_df = month_df.pivot_table(index='Station' , columns=['Date'], values='Min T')\n",
    "    \n",
    "    # Pivot the DataFrame\n",
    "    #pivoted_df = month_df.pivot_table(index='Date' , columns=['Station'], values='Min T')\n",
    "    \n",
    "    # Replace 'NA' with actual NaN values\n",
    "    pivoted_df.replace('NaN', np.nan, inplace=True)\n",
    "    \n",
    "    # Update the dictionary with the pivoted DataFrame\n",
    "    min_regression_ready_dict[month_name] = pivoted_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_regression_1_dict = {}\n",
    "for month_name, month_df in min_regression_ready_dict.items():\n",
    "    \n",
    "    # Step 1: Find the column with the minimum number of missing values\n",
    "    value_missing_onlyone_column = month_df.isna().sum().idxmin()\n",
    "    \n",
    "    #print(value_missing_onlyone_column)\n",
    "    \n",
    "    # Step 2: Calculate the average of the selected column\n",
    "    average_value = month_df[value_missing_onlyone_column].mean()\n",
    "    \n",
    "    #print(average_value)\n",
    "\n",
    "    # Step 3: Replace NaN values in the selected column with the calculated average\n",
    "    month_df[value_missing_onlyone_column].fillna(average_value, inplace=True)\n",
    "    min_regression_1_dict[month_name] = month_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_regression_12_dict ={}\n",
    "for month_name, month_df in min_regression_1_dict.items():\n",
    "    \n",
    "    # Get a list of all column names except the target columns\n",
    "    target_columns = month_df.columns[month_df.isna().any()].tolist()\n",
    "    feature_columns = [col for col in month_df.columns if col not in target_columns]\n",
    "\n",
    "    # Iterate over target columns and impute missing values using regression\n",
    "    for target_col in target_columns:\n",
    "        impute_missing_with_regression(month_df, target_col, feature_columns)\n",
    "        \n",
    "    min_regression_12_dict[month_name] = month_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_regression_123_dict = {}\n",
    "for month_name, month_df in min_regression_12_dict.items():\n",
    "    df_melted_df = month_df.reset_index().melt(id_vars=['Station'], \n",
    "                         var_name='Date', value_name='Min T')\n",
    "    \n",
    "    df_melted_df = df_melted_df[['Date', 'Station', 'Min T']]\n",
    "    \n",
    "    min_regression_123_dict[month_name] = df_melted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "concatenated_df_filled_1990 = pd.concat(min_regression_123_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_filled_1990 = concatenated_df_filled_1990.set_index('Station')\n",
    "station_sort_filled_1990 = station_filled_1990.sort_values(by=['Station', 'Date'], ascending=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_sort_filled_1990.to_csv('G:/fresh_start/main_thesis/data/temp_data/min_station_sort_filled_1990.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date      Min T\n",
      "Station                                \n",
      "1016     1990-01-01 00:00:00  16.865993\n",
      "1016     1990-01-02 00:00:00  12.336708\n",
      "1016     1990-01-03 00:00:00  25.611077\n",
      "1016     1990-01-04 00:00:00   6.503694\n",
      "1016     1990-01-05 00:00:00  12.335740\n",
      "...                      ...        ...\n",
      "1419     2022-12-27 00:00:00   6.000000\n",
      "1419     2022-12-28 00:00:00   5.500000\n",
      "1419     2022-12-29 00:00:00   6.500000\n",
      "1419     2022-12-30 00:00:00   7.500000\n",
      "1419     2022-12-31 00:00:00   8.500000\n",
      "\n",
      "[216954 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(station_sort_filled_1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisKernel",
   "language": "python",
   "name": "thesiskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
