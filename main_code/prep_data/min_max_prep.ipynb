{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_list = pd.read_excel(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\station_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station Geo_region        Station_Name  Elevation        Lat       Long\n",
      "0      1016   Mountain          Sarmathang       2574  27.944561  85.595136\n",
      "1      1024       Hill           Dhulikhel       1543  27.616117  85.565503\n",
      "2      1036       Hill           Panchkhal        857  27.645134  85.620881\n",
      "3      1103   Mountain                Jiri       1877  27.630447  86.232114\n",
      "4      1123       Hill            Manthali        497  27.394703  86.061233\n",
      "5      1124   Mountain               Kabre       1755  27.633333  86.133333\n",
      "6      1206       Hill         Okhaldhunga       1731  27.308121  86.504225\n",
      "7      1212      Terai           Phattepur        101  26.730538  86.934812\n",
      "8      1219   Mountain             Salleri       2383  27.505118  86.586215\n",
      "9      1222       Hill              Diktel       1612  27.212522  86.791886\n",
      "10     1303   Mountain     Chainpur (East)       1277  27.292097  87.316966\n",
      "11     1304       Hill           Pakhribas       1720  27.046316  87.292473\n",
      "12     1307       Hill            Dhankuta       1192  26.983219  87.345956\n",
      "13     1314       Hill           Terhathum       1525  27.123040  87.536190\n",
      "14     1327   Mountain            Khadbari       1064  27.391062  87.204384\n",
      "15     1405   Mountain           Taplejung       1744  27.358611  87.670000\n",
      "16     1419       Hill  Phidim (Panchther)       1157  27.143674  87.765595\n"
     ]
    }
   ],
   "source": [
    "print(stations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first CSV containing Max T data\n",
    "max_temp_df = pd.read_csv(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\max_temp_base.csv')\n",
    "\n",
    "# Load the second CSV containing Min T data\n",
    "min_temp_df = pd.read_csv(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\min_temp_base.csv')\n",
    "\n",
    "# Merge the two DataFrames based on Date and Station\n",
    "combined_max_min_df = pd.merge(max_temp_df, min_temp_df, on=['Date', 'Station'], how='outer')\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_max_min_df.to_csv(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\combined_max_min_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Station  Max T  Min T  Elevation        Lat       Long\n",
      "0  1962-01-01     1206   14.4    3.6     1731.0  27.308121  86.504225\n",
      "1  1962-01-01     1405   14.8    1.3     1744.0  27.358611  87.670000\n",
      "2  1962-01-02     1206   13.1    2.8     1731.0  27.308121  86.504225\n",
      "3  1962-01-02     1405   12.8    2.4     1744.0  27.358611  87.670000\n",
      "4  1962-01-03     1206   13.1    3.6     1731.0  27.308121  86.504225\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on the 'Station' column\n",
    "df_merged = pd.merge(combined_max_min_df, stations_list[['Station', 'Elevation', 'Lat', 'Long']], on='Station', how='left')\n",
    "\n",
    "# Display the merged DataFrame (optional)\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\combined_max_min_stations_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-31\n"
     ]
    }
   ],
   "source": [
    "print(df_merged['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.850000000000005 51.95\n"
     ]
    }
   ],
   "source": [
    "    # Calculate the IQR for 'Max T' column\n",
    "    Q1 = df_merged['Max T'].quantile(0.25)\n",
    "    Q3 = df_merged['Max T'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bounds\n",
    "    lower_bound = Q1 - 3.5 * IQR\n",
    "    upper_bound = Q3 + 3.5 * IQR\n",
    "\n",
    "    print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of max 506.1, max of min 513.0, min of max 0.0, min of min -10.0\n"
     ]
    }
   ],
   "source": [
    "max_max_T = df_merged['Max T'].max()\n",
    "min_max_T = df_merged['Min T'].max()\n",
    "max_min_T = df_merged['Max T'].min()\n",
    "min_min_T = df_merged['Min T'].min()\n",
    "print(f\"max of max {max_max_T}, max of min {min_max_T}, min of max {max_min_T}, min of min {min_min_T}\"  )\n",
    "# Display the oldest da "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 maximum values for 'Max T':\n",
      "28589     506.1\n",
      "39403     500.0\n",
      "268847     45.5\n",
      "205919     45.0\n",
      "205937     45.0\n",
      "Name: Max T, dtype: float64\n",
      "\n",
      "Top 5 minimum values for 'Max T':\n",
      "32612     0.0\n",
      "242497    0.0\n",
      "242548    0.0\n",
      "242582    0.0\n",
      "248417    1.0\n",
      "Name: Max T, dtype: float64\n",
      "\n",
      "Top 5 maximum values for 'Min T':\n",
      "39403     513.0\n",
      "237065     33.5\n",
      "54130      30.0\n",
      "201272     29.5\n",
      "54050      29.1\n",
      "Name: Min T, dtype: float64\n",
      "\n",
      "Top 5 minimum values for 'Min T':\n",
      "197289   -10.0\n",
      "197361   -10.0\n",
      "197451   -10.0\n",
      "197734    -9.6\n",
      "178563    -9.5\n",
      "Name: Min T, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Top 5 maximum values for 'Max T'\n",
    "top_5_max_max_T = df_merged['Max T'].nlargest(5)\n",
    "\n",
    "# Top 5 minimum values for 'Max T'\n",
    "top_5_min_max_T = df_merged['Max T'].nsmallest(5)\n",
    "\n",
    "# Top 5 maximum values for 'Min T'\n",
    "top_5_max_min_T = df_merged['Min T'].nlargest(5)\n",
    "\n",
    "# Top 5 minimum values for 'Min T'\n",
    "top_5_min_min_T = df_merged['Min T'].nsmallest(5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 5 maximum values for 'Max T':\")\n",
    "print(top_5_max_max_T)\n",
    "\n",
    "print(\"\\nTop 5 minimum values for 'Max T':\")\n",
    "print(top_5_min_max_T)\n",
    "\n",
    "print(\"\\nTop 5 maximum values for 'Min T':\")\n",
    "print(top_5_max_min_T)\n",
    "\n",
    "print(\"\\nTop 5 minimum values for 'Min T':\")\n",
    "print(top_5_min_min_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data = pd.read_csv(r'G:\\fresh_start\\paper\\code_paper\\main_data\\raw_data\\combined_max_min_stations_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          9/9/2022\n",
      "Station           1419\n",
      "Max T             45.5\n",
      "Min T             33.5\n",
      "Elevation       2574.0\n",
      "Lat          27.944561\n",
      "Long         87.765595\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(all_raw_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Station' into a dictionary\n",
    "initial_max_dict = dict(tuple(all_raw_data.groupby('Station')))\n",
    "\n",
    "# Dictionaries to store the DataFrames after outlier removal\n",
    "max_outlier_check_dict = {}\n",
    "min_outlier_check_dict = {}\n",
    "\n",
    "# Loop through each station's data\n",
    "for station_name, df_temp in initial_max_dict.items():\n",
    "    \n",
    "    # Calculate the IQR for 'Max T' and 'Min T' columns\n",
    "    max_Q1 = df_temp['Max T'].quantile(0.25)\n",
    "    max_Q3 = df_temp['Max T'].quantile(0.75)\n",
    "    max_IQR = max_Q3 - max_Q1\n",
    "\n",
    "    min_Q1 = df_temp['Min T'].quantile(0.25)\n",
    "    min_Q3 = df_temp['Min T'].quantile(0.75)\n",
    "    min_IQR = min_Q3 - min_Q1\n",
    "\n",
    "    # Define lower and upper bounds for Max T and Min T\n",
    "    max_lower_bound = max_Q1 - 1.5 * max_IQR\n",
    "    max_upper_bound = max_Q3 + 1.5 * max_IQR\n",
    "\n",
    "    min_lower_bound = min_Q1 - 1.5 * min_IQR\n",
    "    min_upper_bound = min_Q3 + 1.5 * min_IQR\n",
    "\n",
    "    # Filter out data points outside the bounds for Max T\n",
    "    df_max_temp_filtered = df_temp[(df_temp['Max T'] >= max_lower_bound) & (df_temp['Max T'] <= max_upper_bound)]\n",
    "    \n",
    "    # Store the filtered DataFrame in the dictionary for Max T\n",
    "    max_outlier_check_dict[station_name] = df_max_temp_filtered\n",
    "\n",
    "    # Filter out data points outside the bounds for Min T\n",
    "    df_min_temp_filtered = df_temp[(df_temp['Min T'] >= min_lower_bound) & (df_temp['Min T'] <= min_upper_bound)]\n",
    "    \n",
    "    # Store the filtered DataFrame in the dictionary for Min T\n",
    "    min_outlier_check_dict[station_name] = df_min_temp_filtered\n",
    "\n",
    "# Check the first few rows of the filtered data for each station\n",
    "for station, df in max_outlier_check_dict.items():\n",
    "    print(f\"Station: {station}\")\n",
    "    print(\"Max\")\n",
    "    print(df.max())\n",
    "    print(\"\\n\")\n",
    "\n",
    "for station, df in min_outlier_check_dict.items():\n",
    "    print(f\"Station: {station}\")\n",
    "    print(\"Min\")\n",
    "    print(df.min())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12836\\3232769362.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Station'] = station_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# List to store each station's DataFrame with the 'Station' column added\n",
    "df_list = []\n",
    "\n",
    "# Loop through each station's filtered DataFrame\n",
    "for station_name, df in max_outlier_check_dict.items():\n",
    "    # Add a new column for the station\n",
    "    df['Station'] = station_name\n",
    "    # Append the DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(df_list)\n",
    "\n",
    "# Export the combined DataFrame to a single CSV file\n",
    "combined_df.to_csv('max_outlier_checked.csv', index=False)\n",
    "\n",
    "print(\"CSV file has been successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date  Station  Max T  Min T  Elevation        Lat       Long\n",
      "0  1/1/1962     1206   14.4    3.6     1731.0  27.308121  86.504225\n",
      "1  1/1/1962     1405   14.8    1.3     1744.0  27.358611  87.670000\n",
      "2  1/2/1962     1206   13.1    2.8     1731.0  27.308121  86.504225\n",
      "3  1/2/1962     1405   12.8    2.4     1744.0  27.358611  87.670000\n",
      "4  1/3/1962     1206   13.1    3.6     1731.0  27.308121  86.504225\n"
     ]
    }
   ],
   "source": [
    "print(all_raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_outlier_check_dict = {}\n",
    "\n",
    "for station_name, df_max_temp in initial_max_dict.items():\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate the IQR for 'Max T' column\n",
    "    Q1 = df_max_temp['Max T'].quantile(0.25)\n",
    "    Q3 = df_max_temp['Max T'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter out data points outside the bounds\n",
    "    df_max_temp = df_max_temp[(df_max_temp['Max T'] >= lower_bound) & (df_max_temp['Max T'] <= upper_bound)]\n",
    "    max_outlier_check_dict[station_name]=df_max_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.5\n"
     ]
    }
   ],
   "source": [
    "max_data = all_raw_data['Min T'].max()\n",
    "print(max_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Station'\n",
    "stations = all_raw_data['Station'].unique()\n",
    "\n",
    "# Create a separate plot for each station\n",
    "for station in stations:\n",
    "    station_data = all_raw_data[all_raw_data['Station'] == station]\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(station_data['Date'], station_data['Max T'], label='Max T')\n",
    "    plt.plot(station_data['Date'], station_data['Min T'], label='Min T')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Temperature (°C)')\n",
    "    plt.title(f'Temperature Trends for Station {station}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
